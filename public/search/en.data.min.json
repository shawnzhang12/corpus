[{"id":0,"href":"/Courses/Optimization-in-Machine-Learning/1.-Review-of-Linear-Algebra/","title":"1. Review of Linear Algebra","parent":"Optimization in ML","content":" Vectors and Matrices \\[\ra = \\begin{bmatrix} 1\\\\ 2\\\\ 3\\\\ \\end{bmatrix} \\in \\R^3, A^{m \\times n} = \\begin{bmatrix}\ra_{11} \u0026amp; a_{12} \u0026amp; \\cdots \u0026amp; a_{1n}\\\\\ra_{21} \u0026amp; a_{22} \u0026amp; \\cdots \u0026amp; a_{2n}\\\\\r\\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\\ra_{m1} \u0026amp; a_{m2} \u0026amp; \\cdots \u0026amp; a_{mn}\r\\end{bmatrix}\r\\] Matrix Operations and Properties Addition The sum of two matrices \\(A \\in \\R^{m \\times n}, B \\in \\R^{m \\times n}\\) is defined as the element-wise sum, i.e.,\n\\(A\u0026#43;B:= \\begin{bmatrix}\ra_{11} \u0026#43; b_{11} \u0026amp; \\cdots \u0026amp; a_{1n} \u0026#43; b_{1n}\\\\\r\\vdots \u0026amp; \u0026amp; \\vdots\\\\\ra_{m1} \u0026#43; b_{m1} \u0026amp; \\cdots \u0026amp; a_{mn} \u0026#43; b_{mn}\r\\end{bmatrix} \\in \\R^{m \\times n}\\) Multiplication Only if neighbouring dimensions match.\n\\[\\underbrace{A}_{n \\times k} \\underbrace{B}_{k \\times m} = \\underbrace{C}_{n \\times m}\\] Identity \\(I_{n} := \\begin{bmatrix}\r1 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0\\\\\r0 \u0026amp; 1 \u0026amp; \\cdots \u0026amp; 0\\\\\r\\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\\r0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 1\r\\end{bmatrix} \\in \\R^{n \\times n}\\) Properties Associativity:\n‚Äã\t\\(\\forall A \\in \\R^{m \\times n}, B \\in \\R^{n \\times p}, C \\in \\R^{p \\times q}: (AB)C = A(BC)\\)\n‚Äã\tFor scalar multiplication, can move scalar values around anywhere.\nDistributivity:\n‚Äã\t\\(\\forall A, B \\in \\R^{m \\times n}, C, D \\in \\R^{n \\times p}: (A \u0026#43; B)C = AC \u0026#43; BC\\)\n‚Äã\t\\(A(C \u0026#43; D) = AC \u0026#43; AD\\)\n‚Äã\tSame scalar distributivity as real numbers.\nMultiplication with the identity matrix:\n‚Äã\t\\(\\forall A \\in \\R^{m \\times n}: I_m A = AI_n = A\\)\nNote that \\(I_m \\neq I_n\\) for \\(m \\neq n\\)\nSystems of Linear Equations Solution Space One solution: Equations are linearly independent, # unknowns = # equations No solution: Some combination of equations contradicts another equation Infinite solutions: Equations are linearly dependent Solving Linear Systems Row-echelon decomposition Linear Independence First defining a linear combination. Consider a vector space \\(V\\) and a finite number of vectors \\(x_1, ...,x_k \\in V\\). Then, every \\(v \\in V\\) of the form\n\\[v=\\lambda_1 x_1 \u0026#43; \\cdots \u0026#43; \\lambda_k x_k = \\sum_{i = 1}^k \\lambda_i x_i \\in V\\] with \\(\\lambda_1, ..., \\lambda_k \\in \\R\\) is a linear combination of the vectors \\(x_1, ..., x_k\\).\nConsider the same vector space \\(V\\). If there is a non-trivial linear combination, such that \\(0 = \\sum_{i=1}^k \\lambda_i x_i\\) with at least one \\(\\lambda_i \\neq 0\\), the vectors \\(x_1, ...,x_k\\) are linearly dependent. Otherwise, if the only solution is the trivial solution \\(\\lambda_1 = ... = \\lambda_k = 0\\) the vectors linearly independent.\nConvex Combination Non-negative \\(\\lambda_i\\) such that \\(\\sum_{i=1}^n \\lambda_i = 1\\).\n","description":"Vectors and Matrices \\[\ra = \\begin{bmatrix} 1\\\\ 2\\\\ 3\\\\ \\end{bmatrix} \\in \\R^3, A^{m \\times n} = \\begin{bmatrix}\ra_{11} \u0026amp; a_{12} \u0026amp; \\cdots \u0026amp; a_{1n}\\\\\ra_{21} \u0026amp; a_{22} \u0026amp; \\cdots \u0026amp; a_{2n}\\\\\r\\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\\ra_{m1} \u0026amp; a_{m2} \u0026amp; \\cdots \u0026amp; a_{mn}\r\\end{bmatrix}\r\\] Matrix Operations and Properties Addition The sum of two matrices \\(A \\in \\R^{m \\times n}, B \\in \\R^{m \\times n}\\) is defined as the element-wise sum, i."},{"id":1,"href":"/BJJGrappling/","title":"BJJ \u0026 Grappling","parent":"Shawn's Docs","content":" Introduction This is bold text, and this is emphasized text.\nVisit the Hugo website!\nHi there.\n","description":"Introduction This is bold text, and this is emphasized text.\nVisit the Hugo website!\nHi there."},{"id":2,"href":"/Leetcode/","title":"Blind 75","parent":"Shawn's Docs","content":" Summary of main topics ","description":" Summary of main topics "},{"id":3,"href":"/Courses/","title":"Courses","parent":"Shawn's Docs","content":"List of Courses Notes:\nDistributed Systems Engineering Leadership Natural Language Computing Optimization in ML 1. Review of Linear Algebra ","description":"List of Courses Notes:\nDistributed Systems Engineering Leadership Natural Language Computing Optimization in ML 1. Review of Linear Algebra "},{"id":4,"href":"/Triathlon/cycle/","title":"Cycling","parent":"Triathlon","content":" General Cycling Tips üòë\n","description":"General Cycling Tips üòë"},{"id":5,"href":"/Courses/Distributed-Systems/","title":"Distributed Systems","parent":"Courses","content":" Introduction Time in distributed systems (lampert clocks, vector clocks) Coordination and agreement Consensus with Paxos and Raft Replication Consistency and transactions Consistent hashing, CAP theorem, content delivery networks Distributed file systems (GFS) MapReduce Peer-to-peer systems, distributed hash tables (DHTs) Blockchains Time-permitting: Special topics Textbooks and Readings ","description":" Introduction Time in distributed systems (lampert clocks, vector clocks) Coordination and agreement Consensus with Paxos and Raft Replication Consistency and transactions Consistent hashing, CAP theorem, content delivery networks Distributed file systems (GFS) MapReduce Peer-to-peer systems, distributed hash tables (DHTs) Blockchains Time-permitting: Special topics Textbooks and Readings "},{"id":6,"href":"/Courses/Engineering-Leadership/","title":"Engineering Leadership","parent":"Courses","content":"What is Engineering Leadership?\nPersonal Learning Goals for Engineering Leadership\nBe able to concretely identify features of \u0026ldquo;leaders\u0026rdquo; that I like Creat a broad leadership path for me to become a better leader ","description":"What is Engineering Leadership?\nPersonal Learning Goals for Engineering Leadership\nBe able to concretely identify features of \u0026ldquo;leaders\u0026rdquo; that I like Creat a broad leadership path for me to become a better leader "},{"id":7,"href":"/Judo/","title":"Judo","parent":"Shawn's Docs","content":"ü•ã\n","description":"ü•ã"},{"id":8,"href":"/Courses/Natural-Language-Computing/","title":"Natural Language Computing","parent":"Courses","content":"\nIntroduction and Motivation How can we get computers to understand what we say and write? Applications include text classification, language translation, speech recognition, natural language understanding, information retrieval,interpretability and Large Language Models.\nThe ultimate human-computer interaction. (Until brain chips become a thing.)\na little deeper: how are sounds and text related, how are words combined to make sentences, meaning and organization\nDefinitions phonology: patterns of speech sounds\nmorphology: changed by inflection\nsyntax: ordering and structure between word and phrases,\nsemantics: study of how meaning is created by words and phrases\npragmatics: the study of meaning in contexts\nAmbiguity - Phonological\nproblem for speech synthesis: read/read\nproblem for speech recognition: too, two\ncontext: how to wreck a nice beach, how to recognize speech\nsyntax ambiguity: buffalo buffalo buffaloooooo\nsyntactic ambiguity: ordering and structure between words, tree parsing\nsemantic ambiguity: every man loves a woman, i made her duck, give me the pot\nmiscellaneous ambiguity: news headlines\nnlp: resolve ambiguity, reason with world knowledge, tend to use probability, turing test\nChatbots: ELIZA pattern matching\napplications:\nmachine translation: interpretation and generation, word-to-word was popular, syntactic ambiguities, definitions, solution use statistical machine translation\nwaveforms and spectrograms, speech recognition\nLecture 2: Corpora, Language Models and Smoothing\nWhat are we counting, how do we count thing?\nCorpora: A body of language data (not the same as vocabulary), useful when occurs naturally, could be domain specific (medical, law) so watch out for bias\nvocab: unique words\nsize of corpus: total number of words\nword order is dependent! need sequence models\nP(car|the old) = 0 if it never appears in past,\nsolution: condition on a fixed number of words, check the sequences \u0026rsquo;the old\u0026rsquo; and \u0026lsquo;old car\u0026rsquo; probably both \u0026gt; 0\nWord prediction: P(w|w_t-1)\nN-grams: token sequences of length N, pros: cheap to train, good baseline\nlanguage model: probabilities of words in an ordered sequence P(w1, w2, w3, \u0026hellip;)\nTerm Count (count): term w in corpus C\nrelative frequency (Fc): relative to the total number of tokens\nprobabilistic chain rule\n\\[P(A,B,C,D)=P(A)P(B|A)P(C|A,B)P(D|A,B,C)\\] simple prediction: approximate conditional probabilities ex. P(food| I like chinese) = P(I like chinese food)/P(I like chinese)\nproblem with chain rule: infinitely long sequences, division by 0, so assume stattistical independence and recent history (markov assumption of previous n grams) bi grams look at one word past\nbi gram probabilities P(want|I) = Count (I want)/Count(I)\nEvaluation of language models\nShannon\u0026rsquo;s method\nshoot darts at board, bigram once hit, another dart board\nShakespeare as a corpus, quadrigrams, increasing context,\nExtrinsic: external measure (task or application), sentiment analysis\nIntrinsic: complexity, other stuff\n","description":"Introduction and Motivation How can we get computers to understand what we say and write? Applications include text classification, language translation, speech recognition, natural language understanding, information retrieval,interpretability and Large Language Models.\nThe ultimate human-computer interaction. (Until brain chips become a thing.)\na little deeper: how are sounds and text related, how are words combined to make sentences, meaning and organization\nDefinitions phonology: patterns of speech sounds\nmorphology: changed by inflection"},{"id":9,"href":"/Courses/Optimization-in-Machine-Learning/","title":"Optimization in ML","parent":"Courses","content":"\nIntroduction and Motivation Humans learn to design algorithms.\nCan algorithms learn to design algorithms? This is the domain of machine learning and discrete optimization. Some applications include: data center management, energy systems, scientific discovery, ridesharing, scheduling, disaster response, college admissions, and so on.\n\u0026ldquo;[\u0026hellip;] the overall value of linear optimization to the economy probably surpasses 5% overall or more than $1 trillion each year in the United States alone.\u0026rdquo; - Birge, J. R. (2022)\nData Center Resource Management Example \\(\\)\rGiven Services \\(S\\) with varying CPU and Memory demands and Machines \\(M\\), how would you design a job scheduler?\rEach machine has multiple processors, so ideally we would want the minimum number of machines active while servicing all the jobs. Each service is on one machine only, and machine is \u0026ldquo;ON\u0026rdquo; if a job is assigned to it. Machines should have enough memory and CPU capacity to run all the services. With our variables, metrics, and constraints defined; we now have an optimization problem. Rewriting in mathematical notation: Variables Metrics Constraints \\(y_m = 1\\) if machine m is used \\(x_{s,m} = 1\\) if service s runs on m \\(x \\in \\{0,1\\}^{S \\times M}, y \\in \\{0,1\\}^M\\) minimize \\(\\sum_{m=1}^{M} y_m\\) \\(\\sum_{m=1}^M x_{s,m} =1 \\: \\forall s\\) \\(y_m \\geq x_{s,m} \\: \\forall s,m\\) \\(\\sum_{s=1}^S \\mathbf{mem}(s) \\cdot x_{s,m} \\leq \\mathbf{MEMCAP}(m) \\: \\forall m\\) \\(\\sum_{s=1}^S \\mathbf{cpu}(s) \\cdot x_{s,m} \\leq \\mathbf{CPUCAP}(m) \\: \\forall m \\) Artificial Intelligence Performs non-trivial tasks as well as or better than humans. Many sub-goals including Perception, Reasoning, Control, and Planning.\nE.g. Speech Recognition: Perception + Reasoning\nAutonomous Driving: Perception + Reasoning + Control + Planning\nGame Playing: Reasoning + Planning\nKnowledge-Based AI Knowledge is represented via logic. We have a knowledge base (set of formulae) and models where all these facts hold. Easy to interpret.\nFundamental Limitations: cannot perform better than human, requires domain knowledge, some things we can\u0026rsquo;t explain to a computer (riding a bicycle)\nData-Based AI = Machine Learning Pros: Don\u0026rsquo;t need to learn from humans, performance improves with more examples\nCons: Hard to interpret, may need many examples\nMachine Learning\nStudy of algorithms that\nimprove their performance P (Optimization) at some task T (Classification, Regression, Clustering) with experience E (Images, Text, Numbers) well-defined learning task: \u0026lt;P,T,E\u0026gt;\nSupervised Learning With sufficient amount of \u0026ldquo;similar\u0026rdquo; data and an expressive model class, minimizing the loss function on the training data should yield an accurate model on unseen test data.\nClassification Elements Data, Model, Loss Decision Tree predict discrete outcomes, LR predicts probabilities of outcomes.\nDecision Trees Find best attribute to split on (e.g. humidity level) Find best split on chosen attribute (e.g. \u0026lt;\u0026gt; 80%) Repeat 1 \u0026amp; 2 until stopping criterion is met (very few data points; node is pure(most training data in node have same label)) Logistic Regression (LR) Parameters: \\(\\beta_0, \\beta_1, ..., \\beta_d\\)\nModel: \\[p(x;\\beta) = \\frac{1}{1 \u0026#43; e^{-(\\beta_0 \u0026#43; \\beta_1 x_1 \u0026#43; ... \u0026#43; \\beta_d x_d)}}\\]\nData: \\(S = {(x_i, y_i)}_{i=1,...,n}\\) , \\(x_i\\): example with d attributes, \\(y_i\\): label\nOptimization: Use Maximum likelihood Estimation (MLE) to find parameters \\(\\beta^*\\) that maximizes the likelihood: \\[\\prod_{i=1}^{n} p(x_i;\\beta)^{y_i} \\times (1 - p(x_i;\\beta))^{1-y_i}\\]\nSupport Vector Machines (SVM) I love them. Uses the Maximum-Margin Principle so that its robust to outliers.\n","description":"Introduction and Motivation Humans learn to design algorithms.\nCan algorithms learn to design algorithms? This is the domain of machine learning and discrete optimization. Some applications include: data center management, energy systems, scientific discovery, ridesharing, scheduling, disaster response, college admissions, and so on.\n\u0026ldquo;[\u0026hellip;] the overall value of linear optimization to the economy probably surpasses 5% overall or more than $1 trillion each year in the United States alone.\u0026rdquo; - Birge, J."},{"id":10,"href":"/Triathlon/run/","title":"Running","parent":"Triathlon","content":" General Running Tips üòë\n","description":"General Running Tips üòë"},{"id":11,"href":"/","title":"Shawn's Docs","parent":"","content":"\nWhat is up homies üìö Check out any of the docs below.\nBJJ \u0026amp; Grappling Blind 75 Courses Distributed Systems Engineering Leadership Natural Language Computing Optimization in ML 1. Review of Linear Algebra Judo Triathlon Cycling Running Swimming ","description":"\nWhat is up homies üìö Check out any of the docs below.\nBJJ \u0026amp; Grappling Blind 75 Courses Distributed Systems Engineering Leadership Natural Language Computing Optimization in ML 1. Review of Linear Algebra Judo Triathlon Cycling Running Swimming "},{"id":12,"href":"/Triathlon/swim/","title":"Swimming","parent":"Triathlon","content":" General Swimming Tips üê¨ Keep Body Horizontal Head Looking Straight Down Enter Stroke Extended, Angle Fingers Flat on the Surface Turn Body to Breathe High Elbow 4 Quick Kicks Per Stroke Keep Non-Pulling Arm Straight in Water until Other Arm almost Enters Workouts Here are some typical workout plans to get started:\nWarm up Rest Time 150m easy, 50m any @ 2:45 ~ 3:00 pace 30s Fill in Thursday Main Rest Time 300 easys Fill in Thursday Swimming Forms Freestyle (Frontcrawl) Fast.\nBackcrawl Chill on the neck.\nBreaststroke Chill on the spine.\nButterfly Fast and furious. Big on the back.\nSwimming Styles (Freestyle) Total Immersion This form of swimming prioritizes reducing drag, keeping streamlined, and increasing stride length instead of frequency. Seems very chill and a good form for comfort (will probably do this when I\u0026rsquo;m 50), but not the method for high speeds.\nSwim Smooth This form of swimming prioritizes speed by propulsion, and is used by elite swimmers and triathletes. This method focuses on increasing stroke frequency and probably consumes more oxygen and energy. Good time to pick it up while I\u0026rsquo;m young.\n","description":"General Swimming Tips üê¨ Keep Body Horizontal Head Looking Straight Down Enter Stroke Extended, Angle Fingers Flat on the Surface Turn Body to Breathe High Elbow 4 Quick Kicks Per Stroke Keep Non-Pulling Arm Straight in Water until Other Arm almost Enters Workouts Here are some typical workout plans to get started:\nWarm up Rest Time 150m easy, 50m any @ 2:45 ~ 3:00 pace 30s Fill in Thursday Main Rest Time 300 easys Fill in Thursday Swimming Forms Freestyle (Frontcrawl) Fast."},{"id":13,"href":"/Triathlon/","title":"Triathlon","parent":"Shawn's Docs","content":" Triathlon Overview Hello all, this section will be a cumulation of all the tips \u0026amp; tricks I\u0026rsquo;ve picked up on my adventure with triathlons üèä‚Äç‚ôÇÔ∏è üö¥‚Äç‚ôÇÔ∏è üö¥‚Äç‚ôÇÔ∏è. I joined the UofT triathlon club to improve my endurance and develop a more balanced body (I see you racket sports and volleyball üôà).\nCheck out each sport below.\nCycling Running Swimming General Competition Tips Welcome to this barren wasteland that won\u0026rsquo;t be populated in the foreseeable future :happy:\nMost Recent Times Swimming: Running: Cycling: Stretchhhhhhhes!!! The core reason why I bother with any physical activity is probably so I don\u0026rsquo;t feel aching pains and injuries all the time. Let\u0026rsquo;s work towards good range of motion, flexibility, and be robust to strains and sprains.\nSwimming Stretches something 30 seconds Running Stretches hip lower back (plsss) hamstrings/quads calves ankles Cycling Stretches I have no idea, probably more hip ","description":"Triathlon Overview Hello all, this section will be a cumulation of all the tips \u0026amp; tricks I\u0026rsquo;ve picked up on my adventure with triathlons üèä‚Äç‚ôÇÔ∏è üö¥‚Äç‚ôÇÔ∏è üö¥‚Äç‚ôÇÔ∏è. I joined the UofT triathlon club to improve my endurance and develop a more balanced body (I see you racket sports and volleyball üôà).\nCheck out each sport below.\nCycling Running Swimming General Competition Tips Welcome to this barren wasteland that won\u0026rsquo;t be populated in the foreseeable future :happy:"},{"id":14,"href":"/tags/","title":"Tags","parent":"Shawn's Docs","content":"","description":""}]