[{"id":0,"href":"/Courses/Natural-Language-Computing/1.-Corpora-Language-Models-Smoothing/","title":"1. Corpora, Language Models, Smoothing","parent":"Natural Language Computing","content":"What are we counting? Tokens and types. Instances of words and kinds of words.\nCorpora: A body of language data. Most useful when occurring naturally. Be aware of bias.\nVocabulary: Set of unique Words\nSize of corpus: Total number of words\nWord Order Matters! Should consider past words, but not ALL past words. \\(P(car|the\\:old) = 0\\) may never appear in the corpus, but \\(P(old|the) \u0026gt; 0\\) and \\(P(car|old) \u0026gt; 0\\) could be true, \\(\\therefore P(the\\:old\\:car) \u0026gt; 0\\).\nSolution: Word prediction with N-gram Models Language Models: The statistical model of a language. Probability of words in an ordered sequence. i.e., \\(P(w_1, w_2, ..., w_n)\\).\nN-grams: token sequences of length N\nGiven probabilities of N-grams, we can compute the conditional probabilities of possible subsequent words. Estimate \\(P(w_t|w_{t-1})\\) from count of \\((w_{t-1}, w_t)\\) in corpus.\nExample: \u0026rsquo;the last word in this sentence is ___\u0026rsquo;. What is the next word? Suppose we know,\n\\[P(is\\:the) \u0026gt; P(is\\:a) \\therefore P(the|is) \u0026gt; P(a|is)\\] Then we would predict \u0026rsquo;the last word in this sentence is the'.\nTerm count (Count): the number of tokens of term \\(w\\) in \\(C\\)\nRelative frequency ( \\(F_C\\)): relative to total number of tokens, basically the fraction of \\(\\frac{count}{total\\:count}\\).\nProbabilistic Chain Rule: \\[P(A,B,C,D)=P(A)P(B|A)P(C|A,B)P(D|A,B,C)\\]\nBut there are many possible solutions, how do we avoid 0 probabilities? We can make a Markov assumption, that only a short linear history of length L is sufficient for word prediction.\nBigram version: \\[P(w_n|w_{1:(n-1)}) \\approx P(w_n|w_{n-1})\\]\nBigram Counts and Probabilities To get likelihoods, we can dividing bigram counts by unigram counts.\nNow we can estimate the probability of whole sentences by adding the start (\u0026lt;s\u0026gt;) and end (\u0026lt;/s\u0026gt;) tags.\n\\[P(\u0026lt;s\u0026gt; I\\:want\\:english\\:food\u0026lt;/s\u0026gt;) \\approx\\] \\[P(I|\u0026lt;s\u0026gt;)P(want|I)P(english|want)P(food|english)P(\u0026lt;/s\u0026gt;|food) \\approx 0.000031\\] Are N-grams still relevant? Often cheaper to train/query than neural LMs. Can be interpolated with neural LMs to often achieve SOTA performance. Occasionally outperform neural LMs. Interpretable and convenient.\nEvaluation of Language Models Shannon\u0026rsquo;s method Sample based on context. RNG those darts. In general, Quadrigrams \u0026gt; Trigrams \u0026gt; Bigrams \u0026gt; Unigrams for appearing more similar to actual texts like Shakespeare. This is because for increasing context, there are fewer possible next words. E.g. \\(P(Gloucester|seek\\:the\\:traitor) = 1\\).\nGoodness of a Model? Extrinsic Evaluation Utility of a language model is often determined in situ (in practice). Take two different LMs and compare them, such as for speech recognition.\nIntrinsic Evaluation Estimate the probability of a corpus \\(P(C)\\).\nMaximum Likelihood Estimate \\(\\theta^* = \\text{argmax}_{\\theta}L_M(\\theta | T), L_M(\\theta|T) = P_{M(\\theta)}(T)\\), where T is the Brown corpus, M is the bigram and unigram tables, and parameters \\(\\theta_{to|want} \\:\\text{is}\\: P(to|want)\\).\nPerplexity Sort of like a \u0026lsquo;branching factor\u0026rsquo;, \\(PP(C) = 2^{-(\\frac{log_2P(C)}{||C||})} = P(C)^{-1/||C||}\\)\nMinimizing perplexity \\(\\equiv\\) Maximizing probability of corpus.\nMax perplexity: Uniform corpus distribution\nLower perplexity \\(\\rightarrow\\) Better Model. Trigram has lowest perplexity compared to bigram.\nZipf and the Natural Distributions in Language Sparseness Longer n-grams will result in more sparsity. Will result in probabilities of 0 when you do multiplications.\nPatterns of Unigrams A few words occur very frequently.\nFrequency of frequencies Word Rankings Zipf\u0026rsquo;s Law We humans are Nlazy.\nSpeaker minimizes effort by having a small vocabulary of common words.\nHearer minimizes effort by having a large vocabulary of less ambiguous words.\nCompromise: frequency and rank are inversely proportional.\n\\[f \\propto \\frac{I}{r} \\quad \\text{i.e., for some k} \\quad f \\cdot r = k\\] Zero prob in Shakespeare, some N-grams are just really rare\nSmoothing mechanisms 1. Add- \\(\\delta\\) smoothing (Laplace) ","description":"What are we counting? Tokens and types. Instances of words and kinds of words.\nCorpora: A body of language data. Most useful when occurring naturally. Be aware of bias.\nVocabulary: Set of unique Words\nSize of corpus: Total number of words\nWord Order Matters! Should consider past words, but not ALL past words. \\(P(car|the\\:old) = 0\\) may never appear in the corpus, but \\(P(old|the) \u0026gt; 0\\) and \\(P(car|old) \u0026gt; 0\\) could be true, \\(\\therefore P(the\\:old\\:car) \u0026gt; 0\\)."},{"id":1,"href":"/Courses/Distributed-Systems/1.-Distributed-Systems-Examples/","title":"1. Distributed Systems Examples","parent":"Distributed Systems","content":" Massively Scalable Key-Value Stores What are key-value stores? Container for key-value pairs (databases) Distributed, multi-component Non-relational Simpler query semantics for increased scalability, speed, availability, and flexibility Why needed?\nBig data. Huge amount of internet users, stored data, frequent updates, fast retrievals. Good for failure detection, failure recovery, replication, memory store, versioning.\nHorizontal scalability: user growth, more nodes Performance: single-record read and write operations Flexibility: adapt to changing data definitions Reliability: provides failure recovery (failure is the norm), thousands of components at play Availability and geo-distribution: Users are worldwide, data can be accessed worldwide Main operations: PUT, GET, and DELETE. That\u0026rsquo;s it.\nSome key-value store in practice: BigTable, HBase, Cassandra, Redis, Dynamo\nBigTable Google, Based on Google File System. Designed for petabyte scale. Tables and tablets (smaller 200MB table partition)\nClient Library Master (controller, single point of failure) Metadata operations Load balancing Tablet server Data operations Master Assigns tablets to tablet servers. Load balancing. Detects addition and expiration of tablet servers.\nTablet Server Manage set of tablets. Handles read and write requests for its tablets. Splits large tablets.\nGFS Distributed file system. BigTable is just using it for data, log storage, replication.\nChubby Coordination, Lock service, metadata storage. A little filesystem itself.\nScheduler Monitoring, failover, allocates resources (usually virtual now).\nTablet location hierarchy Heavy caching. Chubby file \\(\\rightarrow\\) Root tablet with tablet METADATA \\(\\rightarrow\\) More METADATA tablets \\(\\rightarrow\\) User tablets.\nWith 3 levels ( \\(1, 2^{17}, 2^{17}\\)), we have \\(2^{34}\\) tablets\nApache HBase Open source re-implementation of BigTable.\nGFS \\(\\rightarrow\\) HDFS Chubby \\(\\rightarrow\\) ZooKeeper BigTable \\(\\rightarrow\\) HBase MapReduce \\(\\rightarrow\\) Hadoop Architecture Overview Client library Issues put, get, delete operations ZooKeeper (Chubby) Distributed lock service for HBase components Based on ZAB - ZooKeeper Atomic Broadcast (Paxos) HRegion (tablet) tables are split into multiple key-regions HRegion Server (tablet server) processes operations for data / key-regions (tablets) can host multiple key-regions (tablets) HMaster (master) Coordinates components startup, shutdown, failure of region servers opens, closes, assigns, moves regions Not on read or write path Write Ahead Log (WAL) Persists log of operations before anything happens for failure recovery MemStore keep data in main memory, periodically sync to disk HDFS (GFS) underlying distributed file system, table data stored as HFile format Replicates data over multiple data nodes HBase read-path Get ROOT tablet from zookeeper Get metadata of tablets pertaining to table 1 Narrows down to key ranges (which specific tablet) Get value HBase write-path Same four steps for read path Send put to Region Server Write key-value pair to WAL Write key-value pair to MemStore Occasionally flush key-value pair to HDFS (for fast read and write) HBase Scalability add multiple backup master servers avoid single point of failure leader election using zookeeper components can be added on-the-fly Add multiple region servers horizontal scalability master takes care of load balancing When regions get too big, they split, new region registered in zookeeper, master is notified, and meta-table is updated.\nHbase storage unit failure Zookeeper will notice when TCP connection to a server expires and will delete node. Master will take the WAL (how?) and recover the server by replaying the WAL. WAL is stored in the distributed file system.\nSummary on BigTable and Hbase Partitioning of data for horizontal scalability tables \\(\\rightarrow\\) tablets/regions load-balanced amongst region servers Write-Ahead-Log for failure recovery Decouple write from actual I/O of value to disk Use MemStore for fast write Centralized management One master, backup masters with leader election Not involved in read/write path Coordination Zookeeper (Chubby) lock service leader election, failure detection, paxos cache meta-data replies to avoid frequent communication high availability and reliability Distributed file system HDFS stored as Hfiles Data is replicated for availability Chubby Lock Service Stores small amount of information for high availability. Metadata of system.\nBigtable can be recovered as long as Chubby is still available.\nLock Service Operational Model Manages directories, files, read/writes are atomic. Clients maintain sessions, if sessions expires then locks are released. Lock Service Availability five active replicas one replica is designated as master, need to elect master Chubby master and BigTable master are different! Service is up when majority of replicas are running (can communicate with each other) Example: Leader election See who can acquire an exclusive lock on a file first.\nClients concurrently open a file and attempt to acquire the file lock in write mode One client succeeds, writes its name as the leader Rest of the clients (become replicas) subscribe to modification event, read leader from file Cassandra 👁️ Based on Amazon Dynamo, developed by Facebook. Structured storage nodes (no GFS). Decentralized architecture (no master), consistent hashing for load balancing, gossiping to exchange information.\nEach node is responsible for a key interval. Each node has a commit log, memtable and string tables. Can survive failure from commit log, which it occassionally moves data to disk and clears log.\nGlobal Read Path Client sends request to any node The new coordinator node determines responsible replica and sends request Replica queries local file system and returns value to coordinator Coordinator returns value to client Global Write Path Client request, designates coordinator node Coordinate determines replicas, and sends request to them Replicas acknowledge write, and if majority of them updates back with coordinator than coordinator responds to client Incremental Scaling Node picks random location Key range for next node is split in half New node location information is gossiped Failure Node crashes Neighbor nodes determine node crashed: failure gossiped around Recovery of redundant information from other nodes ","description":"Massively Scalable Key-Value Stores What are key-value stores? Container for key-value pairs (databases) Distributed, multi-component Non-relational Simpler query semantics for increased scalability, speed, availability, and flexibility Why needed?\nBig data. Huge amount of internet users, stored data, frequent updates, fast retrievals. Good for failure detection, failure recovery, replication, memory store, versioning.\nHorizontal scalability: user growth, more nodes Performance: single-record read and write operations Flexibility: adapt to changing data definitions Reliability: provides failure recovery (failure is the norm), thousands of components at play Availability and geo-distribution: Users are worldwide, data can be accessed worldwide Main operations: PUT, GET, and DELETE."},{"id":2,"href":"/Courses/Optimization-in-Machine-Learning/1.-Review-of-Linear-Algebra/","title":"1. Review of Linear Algebra","parent":"Optimization in ML","content":" Vectors and Matrices \\[\ra = \\begin{bmatrix} 1\\\\ 2\\\\ 3\\\\ \\end{bmatrix} \\in \\R^3, A^{m \\times n} = \\begin{bmatrix}\ra_{11} \u0026amp; a_{12} \u0026amp; \\cdots \u0026amp; a_{1n}\\\\\ra_{21} \u0026amp; a_{22} \u0026amp; \\cdots \u0026amp; a_{2n}\\\\\r\\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\\ra_{m1} \u0026amp; a_{m2} \u0026amp; \\cdots \u0026amp; a_{mn}\r\\end{bmatrix}\r\\] Matrix Operations and Properties Addition The sum of two matrices \\(A \\in \\R^{m \\times n}, B \\in \\R^{m \\times n}\\) is defined as the element-wise sum, i.e.,\n\\(A\u0026#43;B:= \\begin{bmatrix}\ra_{11} \u0026#43; b_{11} \u0026amp; \\cdots \u0026amp; a_{1n} \u0026#43; b_{1n}\\\\\r\\vdots \u0026amp; \u0026amp; \\vdots\\\\\ra_{m1} \u0026#43; b_{m1} \u0026amp; \\cdots \u0026amp; a_{mn} \u0026#43; b_{mn}\r\\end{bmatrix} \\in \\R^{m \\times n}\\) Multiplication Only if neighbouring dimensions match.\n\\[\\underbrace{A}_{n \\times k} \\underbrace{B}_{k \\times m} = \\underbrace{C}_{n \\times m}\\] Identity \\(I_{n} := \\begin{bmatrix}\r1 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0\\\\\r0 \u0026amp; 1 \u0026amp; \\cdots \u0026amp; 0\\\\\r\\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\\r0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 1\r\\end{bmatrix} \\in \\R^{n \\times n}\\) Properties Associativity:\n​\t\\(\\forall A \\in \\R^{m \\times n}, B \\in \\R^{n \\times p}, C \\in \\R^{p \\times q}: (AB)C = A(BC)\\)\n​\tFor scalar multiplication, can move scalar values around anywhere.\nDistributivity:\n​\t\\(\\forall A, B \\in \\R^{m \\times n}, C, D \\in \\R^{n \\times p}: (A \u0026#43; B)C = AC \u0026#43; BC\\)\n​\t\\(A(C \u0026#43; D) = AC \u0026#43; AD\\)\n​\tSame scalar distributivity as real numbers.\nMultiplication with the identity matrix:\n​\t\\(\\forall A \\in \\R^{m \\times n}: I_m A = AI_n = A\\)\nNote that \\(I_m \\neq I_n\\) for \\(m \\neq n\\)\nSystems of Linear Equations Solution Space One solution: Equations are linearly independent, # unknowns = # equations No solution: Some combination of equations contradicts another equation Infinite solutions: Equations are linearly dependent Solving Linear Systems Row-echelon decomposition Linear Independence First defining a linear combination. Consider a vector space \\(V\\) and a finite number of vectors \\(x_1, ...,x_k \\in V\\). Then, every \\(v \\in V\\) of the form\n\\[v=\\lambda_1 x_1 \u0026#43; \\cdots \u0026#43; \\lambda_k x_k = \\sum_{i = 1}^k \\lambda_i x_i \\in V\\] with \\(\\lambda_1, ..., \\lambda_k \\in \\R\\) is a linear combination of the vectors \\(x_1, ..., x_k\\).\nConsider the same vector space \\(V\\). If there is a non-trivial linear combination, such that \\(0 = \\sum_{i=1}^k \\lambda_i x_i\\) with at least one \\(\\lambda_i \\neq 0\\), the vectors \\(x_1, ...,x_k\\) are linearly dependent. Otherwise, if the only solution is the trivial solution \\(\\lambda_1 = ... = \\lambda_k = 0\\) the vectors linearly independent.\nConvex Combination Non-negative \\(\\lambda_i\\) such that \\(\\sum_{i=1}^n \\lambda_i = 1\\).\n","description":"Vectors and Matrices \\[\ra = \\begin{bmatrix} 1\\\\ 2\\\\ 3\\\\ \\end{bmatrix} \\in \\R^3, A^{m \\times n} = \\begin{bmatrix}\ra_{11} \u0026amp; a_{12} \u0026amp; \\cdots \u0026amp; a_{1n}\\\\\ra_{21} \u0026amp; a_{22} \u0026amp; \\cdots \u0026amp; a_{2n}\\\\\r\\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\\ra_{m1} \u0026amp; a_{m2} \u0026amp; \\cdots \u0026amp; a_{mn}\r\\end{bmatrix}\r\\] Matrix Operations and Properties Addition The sum of two matrices \\(A \\in \\R^{m \\times n}, B \\in \\R^{m \\times n}\\) is defined as the element-wise sum, i."},{"id":3,"href":"/Courses/Optimization-in-Machine-Learning/2.-Optimization/","title":"2. Optimization","parent":"Optimization in ML","content":" General Optimization \\(\\underset{x}{\\text{minimize}}\\: f(x)\\) \\(\\text{subject to} \\quad c_i(x) = 0, i \\in \\mathcal{E}\\) ​ \\(c_i(x) \\geq 0, i \\in \\mathcal{J}\\)\nfor Variables \\(x\\), Objective Function \\(f(x)\\) that satisfies \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\), Constraints \\(\\mathcal{E}, \\mathcal{J}\\) Here\u0026rsquo;s a quick example.\nNotice we don\u0026rsquo;t use strictly greater than. Why? In a continuous domain it is not well-defined. There is no solution to the following optimization as you can get infinitely close to 1, but there is always some \\(\\delta\\) that can be subtracted to get you even closer.\n\\(\\underset{x}{\\text{minimize}}\\: f(x),\\quad \\text{subject to} \\: x \u0026gt; 1\\) Less than or equal to constraints can be converted to greater than or equal to by multiplying the constraint by -1.\nContinuous vs. Discrete Which is typically easier, continuous or discrete optimization?\nAn initial guess might be \u0026ldquo;Oh, discrete cases means limited combinations, so it must be easier right?\u0026rdquo;. Well it turns out that enumeration doesn\u0026rsquo;t get any better as the parameter space increases. I like to think of it as trying to get to the bottom of a hill using stairs (discrete steps) vs. sliding down on a toboggan (continuous). Sorting is an example where discrete optimization is great, and there are methods that aren\u0026rsquo;t just pure enumeration, but that will be for another time.\nCritical Points Global min: lowest point in entire parameter space\nWeak local min: \\(\\leq\\) than points in a small neighborhood around it\nStrong local min: \\(\\lt\\) than points in a small neighborhood around it. $f\u0026rsquo;(x ^{}) = 0, f\u0026rsquo;\u0026rsquo;(x^{}) \u0026gt; 0$.\nInflection: Point where rate of change of the rate of change changes signs (convex to concave or vice versa). For this course, when \\(\\frac{dy}{dx} = \\frac{d^2y}{dx^2} = 0\\).\nConditions for Local Optimality \\(f\u0026#39;(x^*) = 0\\), the first-order necessary condition (FONC) \\(f\u0026#39;\u0026#39;(x^{**}) \\geq 0\\), the second-order necessary condition (SONC) Note: Not all points with zero derivative and a zero second derivative are local minima, such an inflection point.\nHow did we get the necessary conditions? A Taylor approximation that uses only the first two terms of the Taylor expansion.\nProof of the FONC Theorem: if \\(x^*\\) is a local minimizer and f is continuously differentiable around \\(x^*\\), then \\(f\u0026#39;(x^*) = 0\\).\nProof\nPut the proof here\nContinue with Bisection Algorithm and runtimes. ","description":"General Optimization \\(\\underset{x}{\\text{minimize}}\\: f(x)\\) \\(\\text{subject to} \\quad c_i(x) = 0, i \\in \\mathcal{E}\\) ​ \\(c_i(x) \\geq 0, i \\in \\mathcal{J}\\)\nfor Variables \\(x\\), Objective Function \\(f(x)\\) that satisfies \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\), Constraints \\(\\mathcal{E}, \\mathcal{J}\\) Here\u0026rsquo;s a quick example.\nNotice we don\u0026rsquo;t use strictly greater than. Why? In a continuous domain it is not well-defined. There is no solution to the following optimization as you can get infinitely close to 1, but there is always some \\(\\delta\\) that can be subtracted to get you even closer."},{"id":4,"href":"/Courses/Distributed-Systems/2.-Time/","title":"2. Time","parent":"Distributed Systems","content":"hello\n","description":"hello"},{"id":5,"href":"/BJJGrappling/","title":"BJJ \u0026 Grappling","parent":"Shawn's Docs","content":" Let\u0026rsquo;s Get Started, 1 2👏 some basic documentation on techniques, tips and some playmaking.\nSolely documentation, still need to grind out those reps for anything to stick.\nCheck out some nice techniques from the following resources:\nhttps://www.bjjsuccess.com/brazilian-jiu-jitsu-submissions/ ","description":" Let\u0026rsquo;s Get Started, 1 2👏 some basic documentation on techniques, tips and some playmaking.\nSolely documentation, still need to grind out those reps for anything to stick.\nCheck out some nice techniques from the following resources:\nhttps://www.bjjsuccess.com/brazilian-jiu-jitsu-submissions/ "},{"id":6,"href":"/Leetcode/","title":"Blind 75","parent":"Shawn's Docs","content":" Summary of main topics ","description":" Summary of main topics "},{"id":7,"href":"/Courses/","title":"Courses","parent":"Shawn's Docs","content":"List of Courses Notes:\nDistributed Systems 1. Distributed Systems Examples 2. Time Engineering Leadership Natural Language Computing 1. Corpora, Language Models, Smoothing Optimization in ML 1. Review of Linear Algebra 2. Optimization ","description":"List of Courses Notes:\nDistributed Systems 1. Distributed Systems Examples 2. Time Engineering Leadership Natural Language Computing 1. Corpora, Language Models, Smoothing Optimization in ML 1. Review of Linear Algebra 2. Optimization "},{"id":8,"href":"/Triathlon/cycle/","title":"Cycling","parent":"Triathlon","content":" General Cycling Tips 😑\n","description":"General Cycling Tips 😑"},{"id":9,"href":"/Courses/Distributed-Systems/","title":"Distributed Systems","parent":"Courses","content":"\nWhat is a distributed system? Some Definitions: Working definition: system comprised of several physically disjoint compute resources interconnected by a network. Coulouris et al.: hardware or software components located at networked computers communicate and coordinate their actions by passing messages. Tanenbaum: collection of independent computers that appears to its users as a single coherent system. Google Code University: Application that executes a collection of protocols to coordinate the actions of multiple processes on a network, such that all components cooperate together to perform a single or small set of related tasks. We are managing trade-offs and how to navigate the systems design space.\nNode: Physically separable computing entity (process, client, server, machine, container)\nMessage: Unit of communication among nodes (packet, data, RPC (remote procedure call), communication)\nWhy build a distributed system? Centralized system is simpler:\nlocal memory, storage failure model maintenance data security BUT,\nVertical scaling costs more than horizontal scaling (disks, IO channels, sockets) single point of failure resources can be inherently distributed (IOT) Related Disciplines: Networking (Layers, protocols, TCP/IP) Databases (Data management, Transactions, Consistency) Security (Threats, defenses) Parallel Computing (Concurrency, Massively parallel, HPC, NUMA, UMA) Characteristics of distributed systems Reliability Probability of a system to perform its required functions under stated conditions for a specified period of time (to run correctly without failure). Expressed as Mean Time Between Failure (MTBF), failure rate.\nAvailability and high-availability Proportion of time a system is an a functioning state, (1 - unavailable). Expressed as decimal or percentage. Ratio of time usable over entire time.\nClass of 9. E.g. One 9 is available 90% of the time.\nNote: Availability \\(\\neq\\) Reliability (down 1 ms every hour (highly available) vs. down two weeks a year (highly reliable))\nDistributed Systems Design Fallacies The network is reliable. Latency is zero. Bandwidth is infinite. The network is secure. Topology doesn\u0026rsquo;t change. There is one administrator. Transport cost is zero. The network is homogeneous. Course Overview Time in distributed systems (Lampert clocks, vector clocks) Coordination and agreement Consensus with Paxos Replication Consistency and transactions Consistent hashing, CAP theorem, web caching Distributed file systems (GFS) MapReduce, Spark Peer-to-peer systems, distributed hash tables (DHTs) Blockchains Time-permitting: Publish/Subscribe, clouds ","description":"What is a distributed system? Some Definitions: Working definition: system comprised of several physically disjoint compute resources interconnected by a network. Coulouris et al.: hardware or software components located at networked computers communicate and coordinate their actions by passing messages. Tanenbaum: collection of independent computers that appears to its users as a single coherent system. Google Code University: Application that executes a collection of protocols to coordinate the actions of multiple processes on a network, such that all components cooperate together to perform a single or small set of related tasks."},{"id":10,"href":"/Courses/Engineering-Leadership/","title":"Engineering Leadership","parent":"Courses","content":"What is Engineering Leadership?\nPersonal Learning Goals for Engineering Leadership\nBe able to concretely identify features of \u0026ldquo;leaders\u0026rdquo; that I like Create a broad leadership path for me to become a better leader Values\nGrowth Mindset vs Fixed Mindset\nCompetency Ladder\nGiving Good Feedback\nThe micro-yes, a short question that paces that feedback is about to be given, feeling of autonomy specific, data points, objective, specify exactly what it done or not done impact statement, what was the result, brain loves purpose wrap with a question, creates commitment rather than competence also actively pulls for feedback (not wait for push feedback)\nReflection:\nI have set up a filter and everything coming in is always being processed. Very picky filter.\nMy first reaction was that I should use chatgpt, this is because I recently remember a haiku from chatgpt about 404 errors and that chatgpt can do this. I like to avoid thinking when possible, i like keeping my brain at low maintenance. not very surprising considering im a lazy guy. i didnt really feel frustrated during the process, but felt most energized when i tried to think of a 5 syllable phrase to end off the haiku about keep trying or not giving up even after failing. part of me doesnt like being energized cuz it consumes energy.\n","description":"What is Engineering Leadership?\nPersonal Learning Goals for Engineering Leadership\nBe able to concretely identify features of \u0026ldquo;leaders\u0026rdquo; that I like Create a broad leadership path for me to become a better leader Values\nGrowth Mindset vs Fixed Mindset\nCompetency Ladder\nGiving Good Feedback\nThe micro-yes, a short question that paces that feedback is about to be given, feeling of autonomy specific, data points, objective, specify exactly what it done or not done impact statement, what was the result, brain loves purpose wrap with a question, creates commitment rather than competence also actively pulls for feedback (not wait for push feedback)"},{"id":11,"href":"/BJJGrappling/Escapes/","title":"Escapes","parent":"BJJ \u0026 Grappling","content":" Bottom Mount to Closed Guard Escape 1 Keep elbows tight on their thighs to prevent high mount Hip bump to expose their arms X scissor an open arm and pull it into your body Your foot step over to trap their foot Look over one side and hip bump them 45 degrees to one side Get ready to start passing if they don\u0026rsquo;t close guard ","description":" Bottom Mount to Closed Guard Escape 1 Keep elbows tight on their thighs to prevent high mount Hip bump to expose their arms X scissor an open arm and pull it into your body Your foot step over to trap their foot Look over one side and hip bump them 45 degrees to one side Get ready to start passing if they don\u0026rsquo;t close guard "},{"id":12,"href":"/Judo/","title":"Judo","parent":"Shawn's Docs","content":"🥋\n","description":"🥋"},{"id":13,"href":"/Courses/Natural-Language-Computing/","title":"Natural Language Computing","parent":"Courses","content":"\nIntroduction and Motivation How can we get computers to understand what we say and write? Applications include text classification, language translation, speech recognition, natural language understanding, information retrieval,interpretability and Large Language Models.\nThe ultimate human-computer interaction. (Until brain chips become a thing.)\nSome question to think about.\nHow are sounds are text related?\nHow are words combined to make sentences?\nHow are words and phrases used to produce meaning?\nDefinitions Category Definition Example Phonology Study of patterns of speech sounds \u0026ldquo;read\u0026rdquo; \\(\\rightarrow\\) /r iy d/ Morphology How words can be changed by inflection or derivation \u0026ldquo;read\u0026rdquo;, \u0026ldquo;reads\u0026rdquo;,\u0026ldquo;reader\u0026rdquo;, \u0026ldquo;reading\u0026rdquo; Syntax Ordering and structure between words and phrases NounPhrase \\(\\rightarrow\\) article adjective noun Semantics Study of how meaning is created by words and phrases \u0026ldquo;books\u0026rdquo; \\(\\rightarrow\\) 📚 Pragmatics Study of meaning in contexts \u0026ldquo;I\u0026rsquo;m on fire today\u0026rdquo; Why is NLP difficult? Behold the chain of problems. We have some understanding of how language works, but how can we get computers to understand as well?\nPhonological ambiguity ❔ Problem for speech synthesis: \u0026ldquo;read/read\u0026rdquo;, \u0026ldquo;object/object\u0026rdquo;\nProblem for speech recognition: \u0026ldquo;too/two\u0026rdquo;\nHow to recognize speech? How to wreck a nice beach? Nanny? Omae Wa Mou Shindeiru.\nSyntax Resolution ⤵️ The following texts all sound the same, but which one is more likely?\n\u0026ldquo;Buff a low buff a lobe a fellow Buff a low buff a low buff a lobe a fellow\u0026hellip;\u0026rdquo;\n\u0026ldquo;Buffalo buff aloe buff aloe buff aloe buff aloe buff aloe\u0026hellip;\u0026rdquo;\n\u0026ldquo;Buff aloe buff all owe Buffalo buffalo buff a lobe\u0026hellip;\u0026rdquo;\n\u0026ldquo;Buff aloe buff all own Buffalo buff aloe buff a lobe\u0026hellip;\u0026rdquo;\n\u0026ldquo;Buffalo buffalo Buffalo buffalo buffalo Buffalo buffalo Buffalo buffalo\u0026rdquo;\nWe can make sense of sounds with our understanding of syntax and grammar.\nSyntactic Ambiguity ❔ Ordering and structure between words can be grouped into \u0026lsquo;parse tree\u0026rsquo; structures given grammatical \u0026lsquo;rules\u0026rsquo;.\nE.g. \u0026ldquo;I shot an elephant in my pajamas\u0026rdquo;\nIs the elephant wearing your pajamas?\nSemantic Resolution ⤵️ We can resolve ambiguities because of our knowledge of semantics (meaning), but that won\u0026rsquo;t always be the case.\nSemantic Ambiguity ❔ How is meaning created by use of words and phrases?\n\u0026ldquo;Every man loves a woman\u0026rdquo;\n\\(\\forall x \\: man(x) \\exists y: (woman(y) \\wedge loves (x,y))\\) \\(\\exists y: woman(y) \\wedge \\forall x :\\ (man(x) \\rightarrow loves (x,y))\\) \u0026ldquo;I made her duck\u0026rdquo;\nI cooked waterfowl meat for her to eat. I cooked waterfowl that belonged to her. I carved the wooden duck that she owns. I caused her to quickly lower her head. \u0026ldquo;Give me the pot\u0026rdquo;\nIt\u0026rsquo;s time to bake. It\u0026rsquo;s time to get baked. Pragmatics Resolution ⤵️ ❓ No one woman is so popular right? Yeah there isn\u0026rsquo;t.\n🅰️ Every man loves a woman.\n❓What type of food did you make for her?\n🅰️ I cooked waterfowl meat for her to eat.\n❓Are we in Canada? Yes.\n🅰️ It\u0026rsquo;s time to get baked.\nGeneral NLP Involves resolving ambiguity at all levels, reasoning with world knowledge (used to be explicitly encoded in symbolic systems by experts), and tend to use probabilities.\nMachine Translation Interpretation and generation.\nWord-to-word translation? There is disparity of meanings between languages. What defines a nation?Semantic and syntactic ambiguities:\n\u0026ldquo;The spirit is willing, but the flesh is weak\u0026rdquo;\n\\(\\rightarrow\\) Russian \\(\\rightarrow\\) English \\(\\rightarrow\\)\n\u0026ldquo;The vodka is good, but the meat is rotten\u0026rdquo;\nSolution: Statistical Machine Translation Learn statistics on parallel texts. Speech Translation, Spectrograms for another lecture.\n","description":"Introduction and Motivation How can we get computers to understand what we say and write? Applications include text classification, language translation, speech recognition, natural language understanding, information retrieval,interpretability and Large Language Models.\nThe ultimate human-computer interaction. (Until brain chips become a thing.)\nSome question to think about.\nHow are sounds are text related?\nHow are words combined to make sentences?\nHow are words and phrases used to produce meaning?"},{"id":14,"href":"/Courses/Optimization-in-Machine-Learning/","title":"Optimization in ML","parent":"Courses","content":"\nIntroduction and Motivation Humans learn to design algorithms.\nCan algorithms learn to design algorithms? This is the domain of machine learning and discrete optimization. Some applications include: data center management, energy systems, scientific discovery, ridesharing, scheduling, disaster response, college admissions, and so on.\n\u0026ldquo;[\u0026hellip;] the overall value of linear optimization to the economy probably surpasses 5% overall or more than $1 trillion each year in the United States alone.\u0026rdquo; - Birge, J. R. (2022)\nData Center Resource Management Example \\(\\)\rGiven Services \\(S\\) with varying CPU and Memory demands and Machines \\(M\\), how would you design a job scheduler?\rEach machine has multiple processors, so ideally we would want the minimum number of machines active while servicing all the jobs. Each service is on one machine only, and machine is \u0026ldquo;ON\u0026rdquo; if a job is assigned to it. Machines should have enough memory and CPU capacity to run all the services. With our variables, metrics, and constraints defined; we now have an optimization problem. Rewriting in mathematical notation: Variables Metrics Constraints \\(y_m = 1\\) if machine m is used \\(x_{s,m} = 1\\) if service s runs on m \\(x \\in \\{0,1\\}^{S \\times M}, y \\in \\{0,1\\}^M\\) minimize \\(\\sum_{m=1}^{M} y_m\\) \\(\\sum_{m=1}^M x_{s,m} =1 \\: \\forall s\\) \\(y_m \\geq x_{s,m} \\: \\forall s,m\\) \\(\\sum_{s=1}^S \\mathbf{mem}(s) \\cdot x_{s,m} \\leq \\mathbf{MEMCAP}(m) \\: \\forall m\\) \\(\\sum_{s=1}^S \\mathbf{cpu}(s) \\cdot x_{s,m} \\leq \\mathbf{CPUCAP}(m) \\: \\forall m \\) Artificial Intelligence Performs non-trivial tasks as well as or better than humans. Many sub-goals including Perception, Reasoning, Control, and Planning.\nE.g. Speech Recognition: Perception + Reasoning\nAutonomous Driving: Perception + Reasoning + Control + Planning\nGame Playing: Reasoning + Planning\nKnowledge-Based AI Knowledge is represented via logic. We have a knowledge base (set of formulae) and models where all these facts hold. Easy to interpret.\nFundamental Limitations: cannot perform better than human, requires domain knowledge, some things we can\u0026rsquo;t explain to a computer (riding a bicycle)\nData-Based AI = Machine Learning Pros: Don\u0026rsquo;t need to learn from humans, performance improves with more examples\nCons: Hard to interpret, may need many examples\nMachine Learning\nStudy of algorithms that\nimprove their performance P (Optimization) at some task T (Classification, Regression, Clustering) with experience E (Images, Text, Numbers) well-defined learning task: \u0026lt;P,T,E\u0026gt;\nSupervised Learning With sufficient amount of \u0026ldquo;similar\u0026rdquo; data and an expressive model class, minimizing the loss function on the training data should yield an accurate model on unseen test data.\nClassification Elements Data, Model, Loss Decision Tree predict discrete outcomes, LR predicts probabilities of outcomes.\nDecision Trees Find best attribute to split on (e.g. humidity level) Find best split on chosen attribute (e.g. \u0026lt;\u0026gt; 80%) Repeat 1 \u0026amp; 2 until stopping criterion is met (very few data points; node is pure(most training data in node have same label)) Logistic Regression (LR) Parameters: \\(\\beta_0, \\beta_1, ..., \\beta_d\\)\nModel: \\[p(x;\\beta) = \\frac{1}{1 \u0026#43; e^{-(\\beta_0 \u0026#43; \\beta_1 x_1 \u0026#43; ... \u0026#43; \\beta_d x_d)}}\\]\nData: \\(S = {(x_i, y_i)}_{i=1,...,n}\\) , \\(x_i\\): example with d attributes, \\(y_i\\): label\nOptimization: Use Maximum likelihood Estimation (MLE) to find parameters \\(\\beta^*\\) that maximizes the likelihood: \\[\\prod_{i=1}^{n} p(x_i;\\beta)^{y_i} \\times (1 - p(x_i;\\beta))^{1-y_i}\\]\nSupport Vector Machines (SVM) I love them. Uses the Maximum-Margin Principle so that its robust to outliers.\n","description":"Introduction and Motivation Humans learn to design algorithms.\nCan algorithms learn to design algorithms? This is the domain of machine learning and discrete optimization. Some applications include: data center management, energy systems, scientific discovery, ridesharing, scheduling, disaster response, college admissions, and so on.\n\u0026ldquo;[\u0026hellip;] the overall value of linear optimization to the economy probably surpasses 5% overall or more than $1 trillion each year in the United States alone.\u0026rdquo; - Birge, J."},{"id":15,"href":"/BJJGrappling/Positioning/","title":"Positioning","parent":"BJJ \u0026 Grappling","content":" Side Control one arm wedged under head, twist that head same hand grabbing lats other hand connected/on stomach/elbow on hip tippy toe on feet and knees for pressure keep back relatively flat shoulders wide and pressing Dealing with neck frame something something Dealing with hip frame some more steps about elbow to get rid of this Closed Guard ankles crossed want high closed guard when breaking posture use primarily hips and knees to break posture use hand to control/swipe wrists use hand for necktie Mount feet tucked under their butt try to knee up for high mount either smush them or ride high and stay loose be ready to do quick posts with arms or legs to keep position High Mount Good shit will happen here, fill in later S-Mount All pressure on their solar plexus Knees/legs tight to their body, try to get knee under their shoulder so they can\u0026rsquo;t pull their arm out Lean forward to get other leg over if want to armbar Knee on Belly oof pain North-South idk what to do here ","description":" Side Control one arm wedged under head, twist that head same hand grabbing lats other hand connected/on stomach/elbow on hip tippy toe on feet and knees for pressure keep back relatively flat shoulders wide and pressing Dealing with neck frame something something Dealing with hip frame some more steps about elbow to get rid of this Closed Guard ankles crossed want high closed guard when breaking posture use primarily hips and knees to break posture use hand to control/swipe wrists use hand for necktie Mount feet tucked under their butt try to knee up for high mount either smush them or ride high and stay loose be ready to do quick posts with arms or legs to keep position High Mount Good shit will happen here, fill in later S-Mount All pressure on their solar plexus Knees/legs tight to their body, try to get knee under their shoulder so they can\u0026rsquo;t pull their arm out Lean forward to get other leg over if want to armbar Knee on Belly oof pain North-South idk what to do here "},{"id":16,"href":"/Triathlon/run/","title":"Running","parent":"Triathlon","content":" General Running Tips 😑\n","description":"General Running Tips 😑"},{"id":17,"href":"/","title":"Shawn's Docs","parent":"","content":"\nWhat is up homies 📚 Check out any of the docs below.\nBJJ \u0026amp; Grappling Escapes Positioning Submissions Sweeps Takedowns Blind 75 Courses Distributed Systems 1. Distributed Systems Examples 2. Time Engineering Leadership Natural Language Computing 1. Corpora, Language Models, Smoothing Optimization in ML 1. Review of Linear Algebra 2. Optimization Judo White Triathlon Cycling Running Swimming ","description":"\nWhat is up homies 📚 Check out any of the docs below.\nBJJ \u0026amp; Grappling Escapes Positioning Submissions Sweeps Takedowns Blind 75 Courses Distributed Systems 1. Distributed Systems Examples 2. Time Engineering Leadership Natural Language Computing 1. Corpora, Language Models, Smoothing Optimization in ML 1. Review of Linear Algebra 2. Optimization Judo White Triathlon Cycling Running Swimming "},{"id":18,"href":"/BJJGrappling/Submissions/","title":"Submissions","parent":"BJJ \u0026 Grappling","content":" Triangle From Closed Guard Punch arm in Hip up, get ankles crossed Grab ankle, kick off hip and pivot to the side Relock legs Swing opponent arm to the other side Hip up, pull head, squeeze 😴 From Mount We will see Americana (from side control) Take arm out from under head Pin opponent\u0026rsquo;s hand to mat with that arm, use head and shoulders for leverage Bring elbow to neck Get other arm under and connect wrists Pull tight towards body and tilt their elbow up, using the wrists as the turning point (keep wrists on mat) Armbar From Mount CPR mode, target one arm with our one arm under and one arm over Tight S mount, keeping all the pressure with the CPR hands, knee can be behind their shoulder Secure arm, one arm pinning elbow-ish area and other arm grabbing wrist Pull leg over their head, squeeze knees together and keep legs heavy on chest Thumb up, hip up 💀 From Knee on Belly Same knee arm grab through their arm onto their back and pull them into you Get other arm posted behind their back Step over head, and squeeze their arm with your knees Keep their arm secure and turn into armbar Kimura From Closed Guard Get their arm on the ground Sit up like going for hip bump Grab their wrist with closest hand, other arm goes behind then back shoulder Grab your own wrist and turn perpendicular to them, keep your head away from theirs ","description":" Triangle From Closed Guard Punch arm in Hip up, get ankles crossed Grab ankle, kick off hip and pivot to the side Relock legs Swing opponent arm to the other side Hip up, pull head, squeeze 😴 From Mount We will see Americana (from side control) Take arm out from under head Pin opponent\u0026rsquo;s hand to mat with that arm, use head and shoulders for leverage Bring elbow to neck Get other arm under and connect wrists Pull tight towards body and tilt their elbow up, using the wrists as the turning point (keep wrists on mat) Armbar From Mount CPR mode, target one arm with our one arm under and one arm over Tight S mount, keeping all the pressure with the CPR hands, knee can be behind their shoulder Secure arm, one arm pinning elbow-ish area and other arm grabbing wrist Pull leg over their head, squeeze knees together and keep legs heavy on chest Thumb up, hip up 💀 From Knee on Belly Same knee arm grab through their arm onto their back and pull them into you Get other arm posted behind their back Step over head, and squeeze their arm with your knees Keep their arm secure and turn into armbar Kimura From Closed Guard Get their arm on the ground Sit up like going for hip bump Grab their wrist with closest hand, other arm goes behind then back shoulder Grab your own wrist and turn perpendicular to them, keep your head away from theirs "},{"id":19,"href":"/BJJGrappling/Sweeps/","title":"Sweeps","parent":"BJJ \u0026 Grappling","content":" Closed Guard to Mount Hip Bump (optional) Break posture, begin as they regain posture\nElbow up, arm up\nKeep necktie, or switch to cross shoulder\nhip the shit out of them, TORQUE\n","description":"Closed Guard to Mount Hip Bump (optional) Break posture, begin as they regain posture\nElbow up, arm up\nKeep necktie, or switch to cross shoulder\nhip the shit out of them, TORQUE"},{"id":20,"href":"/Triathlon/swim/","title":"Swimming","parent":"Triathlon","content":" General Swimming Tips 🐬 Keep Body Horizontal Head Looking Straight Down Enter Stroke Extended, Angle Fingers Flat on the Surface Turn Body to Breathe High Elbow 4 Quick Kicks Per Stroke Keep Non-Pulling Arm Straight in Water until Other Arm almost Enters Workouts Here are some typical workout plans to get started:\nWarm up Rest Time 150m easy, 50m any @ 2:45 ~ 3:00 pace 30s Fill in Thursday Main Rest Time 300 easys Fill in Thursday Swimming Forms Freestyle (Frontcrawl) Fast.\nBackcrawl Chill on the neck.\nBreaststroke Chill on the spine.\nButterfly Fast and furious. Big on the back.\nSwimming Styles (Freestyle) Total Immersion This form of swimming prioritizes reducing drag, keeping streamlined, and increasing stride length instead of frequency. Seems very chill and a good form for comfort (will probably do this when I\u0026rsquo;m 50), but not the method for high speeds.\nSwim Smooth This form of swimming prioritizes speed by propulsion, and is used by elite swimmers and triathletes. This method focuses on increasing stroke frequency and probably consumes more oxygen and energy. Good time to pick it up while I\u0026rsquo;m young.\n","description":"General Swimming Tips 🐬 Keep Body Horizontal Head Looking Straight Down Enter Stroke Extended, Angle Fingers Flat on the Surface Turn Body to Breathe High Elbow 4 Quick Kicks Per Stroke Keep Non-Pulling Arm Straight in Water until Other Arm almost Enters Workouts Here are some typical workout plans to get started:\nWarm up Rest Time 150m easy, 50m any @ 2:45 ~ 3:00 pace 30s Fill in Thursday Main Rest Time 300 easys Fill in Thursday Swimming Forms Freestyle (Frontcrawl) Fast."},{"id":21,"href":"/BJJGrappling/Takedowns/","title":"Takedowns","parent":"BJJ \u0026 Grappling","content":" Double Leg Takedown Tips If collartied, let go and pop their arms with C clamps real fast:\npop arms with C clamp real fast Get knee between their legs stay upright, head close to hip Wrap arm around thighs/knees and drive forward Keep other leg around 45 degrees and use it as a driving anchor If they don\u0026rsquo;t fall from the initial drive:\nStand up and use that leg to drive diagonally a bit, throwing their legs to the other direction, OR Do the weird pigeon/S mount ankle trip ","description":" Double Leg Takedown Tips If collartied, let go and pop their arms with C clamps real fast:\npop arms with C clamp real fast Get knee between their legs stay upright, head close to hip Wrap arm around thighs/knees and drive forward Keep other leg around 45 degrees and use it as a driving anchor If they don\u0026rsquo;t fall from the initial drive:\nStand up and use that leg to drive diagonally a bit, throwing their legs to the other direction, OR Do the weird pigeon/S mount ankle trip "},{"id":22,"href":"/Triathlon/","title":"Triathlon","parent":"Shawn's Docs","content":" Triathlon Overview Hello all, this section will be a cumulation of all the tips \u0026amp; tricks I\u0026rsquo;ve picked up on my adventure with triathlons 🏊‍♂️ 🚴‍♂️ 🚴‍♂️. I joined the UofT triathlon club to improve my endurance and develop a more balanced body (I see you racket sports and volleyball 🙈).\nCheck out each sport below.\nCycling Running Swimming General Competition Tips Welcome to this barren wasteland that won\u0026rsquo;t be populated in the foreseeable future :happy:\nMost Recent Times Swimming: Running: Cycling: Stretchhhhhhhes!!! The core reason why I bother with any physical activity is probably so I don\u0026rsquo;t feel aching pains and injuries all the time. Let\u0026rsquo;s work towards good range of motion, flexibility, and be robust to strains and sprains.\nSwimming Stretches something 30 seconds Running Stretches hip lower back (plsss) hamstrings/quads calves ankles Cycling Stretches I have no idea, probably more hip ","description":"Triathlon Overview Hello all, this section will be a cumulation of all the tips \u0026amp; tricks I\u0026rsquo;ve picked up on my adventure with triathlons 🏊‍♂️ 🚴‍♂️ 🚴‍♂️. I joined the UofT triathlon club to improve my endurance and develop a more balanced body (I see you racket sports and volleyball 🙈).\nCheck out each sport below.\nCycling Running Swimming General Competition Tips Welcome to this barren wasteland that won\u0026rsquo;t be populated in the foreseeable future :happy:"},{"id":23,"href":"/Judo/White/","title":"White","parent":"Judo","content":" Break Fall chin tucked hips low, try not to roll 45 degree arms, never use elbows huge S L A P P Hip Throw (Ogoshi) Set opponent slightly off balance Grab behind with one arm Also reposition with feet to get MAX hip torque hip throw arm on bicep\nhip throw arm on neck\nall similar\nScarf Hold (Kesa Gatame) OTHER arm around neck (compared to side control) other arm constraint opponent wrist and shoulder legs splayed, good to shuffle so doesn\u0026rsquo;t get trapped head close down and tight to opponent ESCAPE with hip thrust?\ntransition to shove their arm in their face with your head hold\nESCAPE with back roll\ngrab their leg hold\n","description":"Break Fall chin tucked hips low, try not to roll 45 degree arms, never use elbows huge S L A P P Hip Throw (Ogoshi) Set opponent slightly off balance Grab behind with one arm Also reposition with feet to get MAX hip torque hip throw arm on bicep\nhip throw arm on neck\nall similar\nScarf Hold (Kesa Gatame) OTHER arm around neck (compared to side control) other arm constraint opponent wrist and shoulder legs splayed, good to shuffle so doesn\u0026rsquo;t get trapped head close down and tight to opponent ESCAPE with hip thrust?"},{"id":24,"href":"/tags/","title":"Tags","parent":"Shawn's Docs","content":"","description":""}]