---
title: "2. Optimization"
weight: -20	
---

### General Optimization

$\underset{x}{\text{minimize}}\: f(x)$

$\text{subject to} \quad c_i(x) = 0, i \in \mathcal{E}$

â€‹                     $c_i(x) \geq 0, i \in \mathcal{J}$

for Variables $x$, Objective Function $f(x)$ that satisfies $f: \mathbb{R}^n \rightarrow \mathbb{R}$, Constraints $\mathcal{E}, \mathcal{J}$ Here's a quick example.

![](feasible_region.png)

Notice we don't use strictly greater than. Why? In a continuous domain it is not well-defined. There is no solution to the following optimization as you can get infinitely close to 1, but there is always some $\delta$ that can be subtracted to get you even closer. 

$\underset{x}{\text{minimize}}\: f(x),\quad \text{subject to} \: x > 1$

Less than or equal to constraints can be converted to greater than or equal to by multiplying the constraint by -1.

### Continuous vs. Discrete

Which is typically easier, continuous or discrete optimization?

An initial guess might be "Oh, discrete cases means limited combinations, so it must be easier right?". Well it turns out that enumeration doesn't get any better as the parameter space increases. I like to think of it as trying to get to the bottom of a hill using stairs (discrete steps) vs. sliding down on a toboggan (continuous). <u>Sorting</u> is an example where discrete optimization is great, and there are methods that aren't just pure enumeration, but that will be for another time.

### Critical Points

**Global min**: lowest point in entire parameter space

**Weak local min**: $\leq$ than points in a small neighborhood around it

**Strong local min**: $\lt$ than points in a small neighborhood around it

**Inflection**: Point where rate of change *of the* rate of change changes signs (convex to concave or vice versa)











